
# Benchmark de SystÃ¨mes de Transcription Vocale

Ce projet a pour objectif de comparer plusieurs systÃ¨mes de reconnaissance vocale automatique (ASR) pour transcrire des fichiers audio de locuteurs sÃ©nÃ©galais parlant franÃ§ais. Il vise Ã  Ã©valuer la prÃ©cision, la qualitÃ© sÃ©mantique et la robustesse de diffÃ©rents modÃ¨les open source.

---

## ğŸ“Š Objectifs

- Comparer les performances de **Whisper**, **Vosk**, et **Wav2Vec2**
- Utiliser des fichiers audio normalisÃ©s et des transcriptions humaines de rÃ©fÃ©rence
- Calculer des mÃ©triques variÃ©es : WER, CER, BLEU, ROUGE-L, BERTScore, etc.
- Visualiser les rÃ©sultats via une interface web interactive (Streamlit)

---

## ğŸ“ PrÃ©requis

- Python 3.9+
- ffmpeg (installÃ© et accessible via le PATH)
- Environnement virtuel recommandÃ©

```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Structure du projet

```bash
speech_benchmark/
â”œâ”€â”€ audio/                        # Fichiers audio originaux (.mp3, .wav)
â”œâ”€â”€ audio_converted/             # Fichiers audio convertis en wav mono 16kHz
â”œâ”€â”€ references/                  # Transcriptions humaines (.txt)
â”œâ”€â”€ models/                      # ModÃ¨le Vosk franÃ§ais
â”œâ”€â”€ output/                      # CSV contenant les rÃ©sultats
â”œâ”€â”€ src/                         # Scripts Python principaux
â”‚   â”œâ”€â”€ benchmark.py             # Lance les 3 IA et collecte les transcriptions
â”‚   â”œâ”€â”€ eval_key_word.py         # Score mots-clÃ©s retrouvÃ©s
â”‚   â”œâ”€â”€ eval_l2_distance.py      # Distance sÃ©mantique + score global
â”‚   â”œâ”€â”€ eval_semantic_score.py   # BLEU / ROUGE-L / BERTScore
â”‚   â”œâ”€â”€ convert_audio.py         # Conversion audio standardisÃ©e
â”‚   â”œâ”€â”€ app.py                   # Interface Streamlit interactive
â”‚   â””â”€â”€ build_all.py             # Pipeline complet automatique
```

---

## ğŸš€ Utilisation

### 1. Convertir les fichiers audio (si besoin)
```bash
python src/convert_audio.py
```

### 2. Lancer le benchmark complet
```bash
python src/build_all.py
```

### 3. Lancer l'application web
```bash
streamlit run src/app.py
```

---

## ğŸ”¢ MÃ©triques calculÃ©es

| MÃ©trique           | Description                                        |
|--------------------|----------------------------------------------------|
| **WER / CER**      | Taux d'erreur sur mots et caractÃ¨res               |
| **Score Mots-ClÃ©s**| Proportion de mots importants reconnus             |
| **Distance L2**    | Distance sÃ©mantique entre embeddings SBERT         |
| **Score Global**   | Combinaison mots-clÃ©s et proximitÃ© sÃ©mantique       |
| **BLEU / ROUGE-L** | Scores de similaritÃ© textuelle                     |
| **BERTScore**      | SimilaritÃ© sÃ©mantique contextuelle                |

---

## ğŸ“… Auteur

Projet rÃ©alisÃ© dans le cadre d'un benchmark IA vocal pour la transcription du franÃ§ais parlÃ© par des locuteurs sÃ©nÃ©galais. RÃ©alisÃ© avec Python, Streamlit, HuggingFace, Vosk et Whisper.
